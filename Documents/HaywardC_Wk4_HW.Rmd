---
title: "HaywardC_Wk4_HW"
author: "Cynthia Hayward"
date: "April 5, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("C:/Users/cindyHayward/Desktop/ADM/Week_Four/Week4_GIT/Script/Bookbaskets.R")
install.packages("arulesViz")
```

Case Study: Book displays at Flourish and Blotts

The purpose of this assignment is to show how association rules can simulate the book recommendation feature on Amazon.com.

The manager of Flourish and Blotts bookstore is trying to decide the best ways to arrange the book displays for the upcoming summer season in order to increase sales. He gives you a large data set with 90,000+ historical sales transactions and asks you to provide the answers for three questions:

1.	What are the best-selling titles? 
2.	If the manager has to create a book display to appeal to readers who belong to book clubs, what books should be included? He said that the “typical” book club audience would be someone who is reading titles featured by Oprah’s Book Club (https://static.oprah.com/images/o2/201608/201608-obc-complete-list-01a.pdf). 
3.	Can you recommend other books that he should include in display cases? The manager is adamant that your recommendations do not include the following:
a.	Books in a series (i.e. Girl with the Dragon Tattoo series would be an example). The manager already knows series books should be displayed together.
b.	The title “Wild Animus.” You were really surprised by this request and pressed the manager for an explanation. He replied that you should read this blog entry: https://litreactor.com/columns/what-the-hell-is-wild-animus


Instructions on How to Proceed:

Download bookdata.tsv.gz and Bookbaskets.R from Blackboard. The dataset is in tab separated format (.tsv). The .gz extension means the file is compressed due to its large size. If you want to view the raw data, you can download the pdf file titled “bookdata_raw” from Blackboard. The Bookbaskets.R file has codes to import the bookdata.tsv.gz file and convert it into a sparse matrix. Use the .R file to get you started for this week’s homework assignment. 

Create an R markdown file to address the manager’s questions. You are welcomed to embed R code chunks, visualizations and graphics, hyperlinks, and R outputs in the markdown file. Please provide detailed commentary in the markdown file. In particular, your commentaries need to address the following points:

1.	What is the problem/question? How are you going to solve/answer it?
2.	What analysis did you carry out to solve/answer the problem/question?
3.	What are your recommendations to solve/answer the problem/question?

The standard you need to reach for this week is the following: If you look at the R markdown file six months from now, can you understand what you did and can you talk someone else through what you did? The learning goal for this week is to tell a compelling story with all the technical tools and written communication skills you have learned in previous week. Remember that you are casting a wider net now—talking to an audience that may include managers and technical people. So while jargons are acceptable, keep them to a minimum and explain/define your jargons. 


```{r}
inspect(bookbaskets[1:5]) #Examine the first five transactions

basketSizes<-size(bookbaskets) #Calculate number of books purchased by "userID"


bookFreq<-itemFrequency(bookbaskets) #Calculate the support for each book title 


bookCount <- (bookFreq/sum(bookFreq))*sum(basketSizes) 
#   Get the absolute count of book occurrences. 


bookbasket_use<-bookbaskets[basketSizes>1] #Only keep transactions with more than one book purchased. 

bookbasket_use
```
##Lets Experiment with code from class:
```{r}
book_freq_data_frame <- as.data.frame(itemFrequency(bookbaskets))#this will provide a frequency--putting it in a data frame is helpful!

View(book_freq_data_frame)
```

Let's pare this list down a bit to look at the first 15 items.

```{r}
itemFrequency(bookbaskets[, 1:15])# remember it is row, column
```

Plotting the support.

```{r}
itemFrequencyPlot(bookbaskets) 
```

Too much information! Let's impose a rule. Minsup = 10%

```{r}
#itemFrequencyPlot(bookbaskets, support = 0.1)
```

Here is a different take. Let's say we want to look at the "top 20" items.

```{r}
itemFrequencyPlot(bookbaskets, topN = 20) 
```


# Apriori Algorithm

The most frequently used FPA algorithm is Apriori. 

Pro: scalable for large datasets.

Con: computationally intensive. We have to keep comparing the candidate itemsets against the database until no frequent and/or candidate itemsets can be generated. 


**Data format requirement**: Horizontal. One column has the tidset number (tid= transaction ID). Another column has a list of items.

**Method**

1. Initialize by scanning the database once to get frequent 1-itemset
2. Generate length (k+1) candidate itemsets from length k frequent itemsets
3. Test the candidate itemsets against the database. Prune candidate itemsets based on the minimum support threshold (minsup).
4. Terminate when no frequent or candidate set can be generated.

## Exploring apriori() in arules Package

```{r}
#?apriori
```

### Default parameter settings

support = 0.1 (or 10%)
confidence = 0.8 (or 80%)
maxlen = maximum number of items in a rule. Default is 10.
minlen = minimum number of items in a rule. Default is 1.


Let's try the default parameter settings first.

```{r}
apriori(bookbaskets)
```

Not a single rule found! Let's try again with some tweakings to the parameter settings.

```{r} 
bookbasketsrules <- apriori(bookbaskets, parameter = list(support =
                          0.001, confidence = 0.8, minlen = 2)) 
```

Let's count the number of rules found

```{r}
print(bookbasketsrules) 
```

## Evaluating Performance

Let's look at the number of rules and number of items per rule.

```{r}
summary(bookbasketsrules)
```

Let's see what we found:

2-itemset: 1 rules

3-itemset: 52 rules

4-itemset: 27 rules

5-itemset: 14 rules

Total = 84 rules. 


Let's look at the first 10 rules. Please note the rules are not listed in the order of importance. lhs = Left hand side...meaning if they buy on the left side, they wiil buy what is on the right side.

```{r}
inspect(bookbasketsrules[1:10]) 
```

### Let's Talk About "Lift"!

In the context of our current analysis, lift measures "how much more likely an item is to be purchased relative to its typical purchase rate, given that you know another item has been purchased" (Lantz 2013, p. 261).

```
Lift: How important is the rule when compared against random chance?

Lift: Confidence/Support
```


For example:

```
Lift (honey --> whole milk) = Confidence (honey --> whole milk)/Support (whole milk)

Confidence (honey --> whole milk) = 0.7333

Support (whole milk) = 0.2556. 

Lift = 0.4108/0.2556 = 2.87
```


## Improving Performance

Let's sort the rules by lift.

```{r}
bookbasketsrules_sorted <- sort(bookbasketsrules, by = "lift")
#inspect(groceryrules_sorted)
```

And now by lift and confidence.

```{r}
bookbasketsrules_sorted <-sort(bookbasketsrules, by = c("lift", "confidence"))
#inspect(bookbasketsrules_sorted)
```

### Strong Rules. Actionable Rules.

A **strong** rule has high support and confidence.

An **actionable** rule is one you can act on. Lift can play a major role in answering this question.

Remember that there are always more trivial rules than non-trivial, actionable rules.

### An Example: It is Soup Season!

Here we are looking at the subsets of rules containing "soups" items. Winter is approaching, and we know people buy soup during colder months. What else are they buying with soup?

```{r}
qspace_rules <- subset(bookbasketsrules_sorted, items %in% " q-space")
inspect(pokemon_rules)
```


Let's write the rules out to a CSV file.

```{r}
write(bookbasketsrules_sorted, file = "C:/Users/cindyHayward/Desktop/ADM/Week_Four/Week4_GIT/Documents/bookbaksetsrules.csv",
      sep = ",", quote = TRUE, row.names = FALSE)
```

Looking at the rules in a data frame.

```{r}
bookbaskets_rules_df <- as(bookbasketsrules_sorted, "data.frame")
View(bookbaskets_rules_df)
```

# Using arulesViz Package to Visualize the "Mined" Rules

## Scatterplot

```{r}
library(arulesViz)
plot(bookbasketsrules)
```

##A two-key plot

Looking at the k-itemset rules by different coding colors.

order 3: 3 itemset rules
order 4: 4 itemset rules
and so on...

```{r}
library(arulesViz)
plot(bookbasketsrules, shading="order", control=list(main="Two-key plot"))
```

## Grouped Matrix Plot

The rules are grouped using k-means clustering. Default quality measure is lift. Default plot shows 20 rules for the antecedents (LHS or left hand side).

```{r}
plot(bookbasketsrules, method="grouped")
```


